{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553ac533",
   "metadata": {},
   "source": [
    "## Table Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859d935",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3633bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Extraction for Financial Documents\n",
    "# Comparing Camelot (lattice/stream) vs pdfplumber table detection\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Table extraction libraries\n",
    "import camelot\n",
    "import pdfplumber\n",
    "from pdfplumber import PDF\n",
    "\n",
    "# For visualization and analysis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edc8810",
   "metadata": {},
   "source": [
    "### Configuration and Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "056557a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "raw_pdf_dir = \"../data/raw/MSFT/10-K/PDFs\"\n",
    "table_output_dir = \"../data/tables/MSFT\"\n",
    "\n",
    "# Create output directory structure\n",
    "os.makedirs(table_output_dir, exist_ok=True)\n",
    "\n",
    "# Table extraction settings\n",
    "CAMELOT_SETTINGS = {\n",
    "    'lattice': {\n",
    "        'line_scale': 40,\n",
    "        'copy_text': ['v'],\n",
    "        'split_text': True,\n",
    "        'flag_size': True,\n",
    "        'strip_text': '\\n'\n",
    "    },\n",
    "    'stream': {\n",
    "        'edge_tol': 500,\n",
    "        'row_tol': 10,\n",
    "        'column_tol': 10,\n",
    "        'copy_text': ['v'],\n",
    "        'split_text': True,\n",
    "        'flag_size': True,\n",
    "        'strip_text': '\\n'\n",
    "    }\n",
    "}\n",
    "\n",
    "PDFPLUMBER_SETTINGS = {\n",
    "    'vertical_strategy': 'lines',\n",
    "    'horizontal_strategy': 'lines',\n",
    "    'snap_tolerance': 3,\n",
    "    'join_tolerance': 3,\n",
    "    'edge_min_length': 3,\n",
    "    'min_words_vertical': 3,\n",
    "    'min_words_horizontal': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e6667",
   "metadata": {},
   "source": [
    "### Data Classes for Table Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f09f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from enum import Enum\n",
    "\n",
    "class TableMethod(Enum):\n",
    "    CAMELOT_LATTICE = \"camelot_lattice\"\n",
    "    CAMELOT_STREAM = \"camelot_stream\"\n",
    "    PDFPLUMBER = \"pdfplumber\"\n",
    "\n",
    "@dataclass\n",
    "class TableExtractionResult:\n",
    "    \"\"\"Data class for table extraction results\"\"\"\n",
    "    method: TableMethod\n",
    "    page_number: int\n",
    "    table_index: int\n",
    "    confidence: Optional[float]\n",
    "    accuracy: Optional[float]\n",
    "    rows: int\n",
    "    columns: int\n",
    "    raw_data: pd.DataFrame\n",
    "    extraction_time: float\n",
    "    success: bool\n",
    "    error_message: Optional[str] = None\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'method': self.method.value,\n",
    "            'page_number': self.page_number,\n",
    "            'table_index': self.table_index,\n",
    "            'confidence': self.confidence,\n",
    "            'accuracy': self.accuracy,\n",
    "            'rows': self.rows,\n",
    "            'columns': self.columns,\n",
    "            'extraction_time': self.extraction_time,\n",
    "            'success': self.success,\n",
    "            'error_message': self.error_message\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class TableComparison:\n",
    "    \"\"\"Data class for comparing table extraction methods\"\"\"\n",
    "    page_number: int\n",
    "    table_index: int\n",
    "    methods_compared: List[TableMethod]\n",
    "    best_method: Optional[TableMethod]\n",
    "    quality_scores: Dict[str, float]\n",
    "    row_column_preservation: Dict[str, Dict[str, int]]\n",
    "    recommendations: List[str]\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe2d801",
   "metadata": {},
   "source": [
    "### Data Classes for Table Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01cfbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from enum import Enum\n",
    "\n",
    "class TableMethod(Enum):\n",
    "    CAMELOT_LATTICE = \"camelot_lattice\"\n",
    "    CAMELOT_STREAM = \"camelot_stream\"\n",
    "    PDFPLUMBER = \"pdfplumber\"\n",
    "\n",
    "@dataclass\n",
    "class TableExtractionResult:\n",
    "    \"\"\"Data class for table extraction results\"\"\"\n",
    "    method: TableMethod\n",
    "    page_number: int\n",
    "    table_index: int\n",
    "    confidence: Optional[float]\n",
    "    accuracy: Optional[float]\n",
    "    rows: int\n",
    "    columns: int\n",
    "    raw_data: pd.DataFrame\n",
    "    extraction_time: float\n",
    "    success: bool\n",
    "    error_message: Optional[str] = None\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'method': self.method.value,\n",
    "            'page_number': self.page_number,\n",
    "            'table_index': self.table_index,\n",
    "            'confidence': self.confidence,\n",
    "            'accuracy': self.accuracy,\n",
    "            'rows': self.rows,\n",
    "            'columns': self.columns,\n",
    "            'extraction_time': self.extraction_time,\n",
    "            'success': self.success,\n",
    "            'error_message': self.error_message\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class TableComparison:\n",
    "    \"\"\"Data class for comparing table extraction methods\"\"\"\n",
    "    page_number: int\n",
    "    table_index: int\n",
    "    methods_compared: List[TableMethod]\n",
    "    best_method: Optional[TableMethod]\n",
    "    quality_scores: Dict[str, float]\n",
    "    row_column_preservation: Dict[str, Dict[str, int]]\n",
    "    recommendations: List[str]\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'page_number': self.page_number,\n",
    "            'table_index': self.table_index,\n",
    "            'methods_compared': [method.value for method in self.methods_compared],  # Convert enum to string\n",
    "            'best_method': self.best_method.value if self.best_method else None,  # Convert enum to string\n",
    "            'quality_scores': self.quality_scores,\n",
    "            'row_column_preservation': self.row_column_preservation,\n",
    "            'recommendations': self.recommendations\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735e8b9",
   "metadata": {},
   "source": [
    "### Camelot Table Extraction Functions\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3eac192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_camelot_lattice(pdf_path: str, page_num: int = None) -> List[TableExtractionResult]:\n",
    "    \"\"\"Extract tables using Camelot lattice mode\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Extract tables with lattice mode\n",
    "        tables = camelot.read_pdf(\n",
    "            pdf_path, \n",
    "            pages=str(page_num) if page_num else 'all',\n",
    "            flavor='lattice',\n",
    "            **CAMELOT_SETTINGS['lattice']\n",
    "        )\n",
    "        \n",
    "        extraction_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        for i, table in enumerate(tables):\n",
    "            result = TableExtractionResult(\n",
    "                method=TableMethod.CAMELOT_LATTICE,\n",
    "                page_number=table.page,\n",
    "                table_index=i,\n",
    "                confidence=table.accuracy,\n",
    "                accuracy=table.accuracy,\n",
    "                rows=len(table.df),\n",
    "                columns=len(table.df.columns),\n",
    "                raw_data=table.df,\n",
    "                extraction_time=extraction_time,\n",
    "                success=True\n",
    "            )\n",
    "            results.append(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        result = TableExtractionResult(\n",
    "            method=TableMethod.CAMELOT_LATTICE,\n",
    "            page_number=page_num or 0,\n",
    "            table_index=0,\n",
    "            confidence=None,\n",
    "            accuracy=None,\n",
    "            rows=0,\n",
    "            columns=0,\n",
    "            raw_data=pd.DataFrame(),\n",
    "            extraction_time=0,\n",
    "            success=False,\n",
    "            error_message=str(e)\n",
    "        )\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def extract_tables_camelot_stream(pdf_path: str, page_num: int = None) -> List[TableExtractionResult]:\n",
    "    \"\"\"Extract tables using Camelot stream mode\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Extract tables with stream mode\n",
    "        tables = camelot.read_pdf(\n",
    "            pdf_path, \n",
    "            pages=str(page_num) if page_num else 'all',\n",
    "            flavor='stream',\n",
    "            **CAMELOT_SETTINGS['stream']\n",
    "        )\n",
    "        \n",
    "        extraction_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        for i, table in enumerate(tables):\n",
    "            result = TableExtractionResult(\n",
    "                method=TableMethod.CAMELOT_STREAM,\n",
    "                page_number=table.page,\n",
    "                table_index=i,\n",
    "                confidence=table.accuracy,\n",
    "                accuracy=table.accuracy,\n",
    "                rows=len(table.df),\n",
    "                columns=len(table.df.columns),\n",
    "                raw_data=table.df,\n",
    "                extraction_time=extraction_time,\n",
    "                success=True\n",
    "            )\n",
    "            results.append(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        result = TableExtractionResult(\n",
    "            method=TableMethod.CAMELOT_STREAM,\n",
    "            page_number=page_num or 0,\n",
    "            table_index=0,\n",
    "            confidence=None,\n",
    "            accuracy=None,\n",
    "            rows=0,\n",
    "            columns=0,\n",
    "            raw_data=pd.DataFrame(),\n",
    "            extraction_time=0,\n",
    "            success=False,\n",
    "            error_message=str(e)\n",
    "        )\n",
    "        results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0b9c2",
   "metadata": {},
   "source": [
    "### PDFplumber Table Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8893e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_pdfplumber(pdf_path: str, page_num: int = None) -> List[TableExtractionResult]:\n",
    "    \"\"\"Extract tables using pdfplumber\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            pages_to_process = [page_num] if page_num else range(len(pdf.pages))\n",
    "            \n",
    "            for page_idx in pages_to_process:\n",
    "                page = pdf.pages[page_idx]\n",
    "                \n",
    "                # Extract tables from the page\n",
    "                tables = page.extract_tables(**PDFPLUMBER_SETTINGS)\n",
    "                \n",
    "                extraction_time = (datetime.now() - start_time).total_seconds()\n",
    "                \n",
    "                for i, table in enumerate(tables):\n",
    "                    if table:  # Check if table is not empty\n",
    "                        # Convert to DataFrame\n",
    "                        df = pd.DataFrame(table[1:], columns=table[0] if table[0] else None)\n",
    "                        \n",
    "                        result = TableExtractionResult(\n",
    "                            method=TableMethod.PDFPLUMBER,\n",
    "                            page_number=page_idx + 1,\n",
    "                            table_index=i,\n",
    "                            confidence=None,  # pdfplumber doesn't provide confidence\n",
    "                            accuracy=None,\n",
    "                            rows=len(df),\n",
    "                            columns=len(df.columns),\n",
    "                            raw_data=df,\n",
    "                            extraction_time=extraction_time,\n",
    "                            success=True\n",
    "                        )\n",
    "                        results.append(result)\n",
    "                        \n",
    "    except Exception as e:\n",
    "        result = TableExtractionResult(\n",
    "            method=TableMethod.PDFPLUMBER,\n",
    "            page_number=page_num or 0,\n",
    "            table_index=0,\n",
    "            confidence=None,\n",
    "            accuracy=None,\n",
    "            rows=0,\n",
    "            columns=0,\n",
    "            raw_data=pd.DataFrame(),\n",
    "            extraction_time=0,\n",
    "            success=False,\n",
    "            error_message=str(e)\n",
    "        )\n",
    "        results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b636b168",
   "metadata": {},
   "source": [
    "### Table Quality Assessment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f81f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_table_quality(df: pd.DataFrame, method: TableMethod) -> Dict[str, float]:\n",
    "    \"\"\"Assess the quality of an extracted table\"\"\"\n",
    "    if df.empty:\n",
    "        return {'completeness': 0, 'structure_preservation': 0, 'data_quality': 0}\n",
    "    \n",
    "    # Completeness: percentage of non-empty cells\n",
    "    total_cells = df.size\n",
    "    non_empty_cells = df.notna().sum().sum()\n",
    "    completeness = (non_empty_cells / total_cells) * 100 if total_cells > 0 else 0\n",
    "    \n",
    "    # Structure preservation: consistency in row/column structure\n",
    "    row_lengths = df.notna().sum(axis=1)\n",
    "    structure_preservation = 100 - (row_lengths.std() / row_lengths.mean() * 100) if row_lengths.mean() > 0 else 0\n",
    "    structure_preservation = max(0, structure_preservation)\n",
    "    \n",
    "    # Data quality: based on method-specific heuristics\n",
    "    data_quality = 0\n",
    "    if method == TableMethod.CAMELOT_LATTICE:\n",
    "        # Lattice mode is good for bordered tables\n",
    "        data_quality = min(100, completeness + 10)\n",
    "    elif method == TableMethod.CAMELOT_STREAM:\n",
    "        # Stream mode is good for borderless tables\n",
    "        data_quality = min(100, completeness + 5)\n",
    "    else:  # PDFplumber\n",
    "        # PDFplumber is good for complex layouts\n",
    "        data_quality = min(100, completeness + 15)\n",
    "    \n",
    "    return {\n",
    "        'completeness': completeness,\n",
    "        'structure_preservation': structure_preservation,\n",
    "        'data_quality': data_quality,\n",
    "        'overall_score': (completeness + structure_preservation + data_quality) / 3\n",
    "    }\n",
    "\n",
    "def detect_table_type(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Detect the type of financial table\"\"\"\n",
    "    if df.empty:\n",
    "        return 'empty'\n",
    "    \n",
    "    # Look for common financial statement indicators\n",
    "    text_content = ' '.join(df.astype(str).values.flatten()).lower()\n",
    "    \n",
    "    if any(keyword in text_content for keyword in ['balance sheet', 'assets', 'liabilities', 'equity']):\n",
    "        return 'balance_sheet'\n",
    "    elif any(keyword in text_content for keyword in ['income statement', 'revenue', 'expenses', 'net income']):\n",
    "        return 'income_statement'\n",
    "    elif any(keyword in text_content for keyword in ['cash flow', 'operating activities', 'investing activities']):\n",
    "        return 'cash_flow_statement'\n",
    "    elif any(keyword in text_content for keyword in ['financial', 'statement', 'consolidated']):\n",
    "        return 'financial_statement'\n",
    "    else:\n",
    "        return 'general_table'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85b123",
   "metadata": {},
   "source": [
    "### Table Comparison and Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9972fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_table_extractions(results: List[TableExtractionResult]) -> List[TableComparison]:\n",
    "    \"\"\"Compare table extraction results across different methods\"\"\"\n",
    "    comparisons = []\n",
    "    \n",
    "    # Group results by page and table index\n",
    "    grouped_results = {}\n",
    "    for result in results:\n",
    "        key = (result.page_number, result.table_index)\n",
    "        if key not in grouped_results:\n",
    "            grouped_results[key] = []\n",
    "        grouped_results[key].append(result)\n",
    "    \n",
    "    # Compare results for each table\n",
    "    for (page_num, table_idx), method_results in grouped_results.items():\n",
    "        if len(method_results) < 2:\n",
    "            continue  # Need at least 2 methods to compare\n",
    "        \n",
    "        # Calculate quality scores for each method\n",
    "        quality_scores = {}\n",
    "        row_column_preservation = {}\n",
    "        \n",
    "        for result in method_results:\n",
    "            if result.success and not result.raw_data.empty:\n",
    "                quality_scores[result.method.value] = assess_table_quality(result.raw_data, result.method)\n",
    "                row_column_preservation[result.method.value] = {\n",
    "                    'rows': result.rows,\n",
    "                    'columns': result.columns\n",
    "                }\n",
    "        \n",
    "        # Determine best method\n",
    "        best_method = None\n",
    "        best_score = 0\n",
    "        if quality_scores:\n",
    "            best_method_name = max(quality_scores.keys(), \n",
    "                                 key=lambda k: quality_scores[k]['overall_score'])\n",
    "            best_score = quality_scores[best_method_name]['overall_score']\n",
    "            best_method = TableMethod(best_method_name)\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = generate_recommendations(quality_scores, row_column_preservation)\n",
    "        \n",
    "        comparison = TableComparison(\n",
    "            page_number=page_num,\n",
    "            table_index=table_idx,\n",
    "            methods_compared=[result.method for result in method_results],\n",
    "            best_method=best_method,\n",
    "            quality_scores=quality_scores,\n",
    "            row_column_preservation=row_column_preservation,\n",
    "            recommendations=recommendations\n",
    "        )\n",
    "        comparisons.append(comparison)\n",
    "    \n",
    "    return comparisons\n",
    "\n",
    "def generate_recommendations(quality_scores: Dict, row_column_preservation: Dict) -> List[str]:\n",
    "    \"\"\"Generate recommendations based on comparison results\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    if not quality_scores:\n",
    "        return [\"No successful extractions to compare\"]\n",
    "    \n",
    "    # Find best and worst methods\n",
    "    best_method = max(quality_scores.keys(), key=lambda k: quality_scores[k]['overall_score'])\n",
    "    worst_method = min(quality_scores.keys(), key=lambda k: quality_scores[k]['overall_score'])\n",
    "    \n",
    "    recommendations.append(f\"Best method: {best_method} (score: {quality_scores[best_method]['overall_score']:.1f})\")\n",
    "    recommendations.append(f\"Worst method: {worst_method} (score: {quality_scores[worst_method]['overall_score']:.1f})\")\n",
    "    \n",
    "    # Method-specific recommendations\n",
    "    if 'camelot_lattice' in quality_scores and 'camelot_stream' in quality_scores:\n",
    "        lattice_score = quality_scores['camelot_lattice']['overall_score']\n",
    "        stream_score = quality_scores['camelot_stream']['overall_score']\n",
    "        \n",
    "        if lattice_score > stream_score + 10:\n",
    "            recommendations.append(\"Table has clear borders - lattice mode preferred\")\n",
    "        elif stream_score > lattice_score + 10:\n",
    "            recommendations.append(\"Table is borderless - stream mode preferred\")\n",
    "        else:\n",
    "            recommendations.append(\"Both Camelot modes perform similarly - consider hybrid approach\")\n",
    "    \n",
    "    # Structure preservation analysis\n",
    "    if len(row_column_preservation) > 1:\n",
    "        row_counts = [data['rows'] for data in row_column_preservation.values()]\n",
    "        col_counts = [data['columns'] for data in row_column_preservation.values()]\n",
    "        \n",
    "        if max(row_counts) - min(row_counts) > 2:\n",
    "            recommendations.append(\"Significant variation in row count - check for merged cells\")\n",
    "        if max(col_counts) - min(col_counts) > 1:\n",
    "            recommendations.append(\"Significant variation in column count - check for column detection\")\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328788ad",
   "metadata": {},
   "source": [
    "### Hybrid Extractor Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "125247fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_extractor(pdf_path: str, page_num: int = None) -> List[TableExtractionResult]:\n",
    "    \"\"\"Create a hybrid extractor that chooses the best method based on heuristics\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        # First, try to detect if the page has ruling lines\n",
    "        has_ruling_lines = detect_ruling_lines(pdf_path, page_num)\n",
    "        \n",
    "        if has_ruling_lines:\n",
    "            print(f\"  📏 Detected ruling lines - using Camelot lattice mode\")\n",
    "            results.extend(extract_tables_camelot_lattice(pdf_path, page_num))\n",
    "        else:\n",
    "            print(f\"  📝 No ruling lines detected - using Camelot stream mode\")\n",
    "            results.extend(extract_tables_camelot_stream(pdf_path, page_num))\n",
    "        \n",
    "        # Always try pdfplumber as backup\n",
    "        print(f\"  🔧 Running pdfplumber as backup method\")\n",
    "        pdfplumber_results = extract_tables_pdfplumber(pdf_path, page_num)\n",
    "        results.extend(pdfplumber_results)\n",
    "        \n",
    "        # Compare results and select best\n",
    "        if len(results) > 1:\n",
    "            comparisons = compare_table_extractions(results)\n",
    "            if comparisons:\n",
    "                best_comparison = comparisons[0]  # Assuming first comparison is relevant\n",
    "                if best_comparison.best_method:\n",
    "                    print(f\"  🏆 Best method identified: {best_comparison.best_method.value}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Hybrid extraction failed: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def detect_ruling_lines(pdf_path: str, page_num: int = None) -> bool:\n",
    "    \"\"\"Detect if a page has ruling lines (simple heuristic)\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            page = pdf.pages[page_num - 1] if page_num else pdf.pages[0]\n",
    "            \n",
    "            # Get lines from the page\n",
    "            lines = page.lines\n",
    "            \n",
    "            # Count horizontal and vertical lines\n",
    "            horizontal_lines = [line for line in lines if abs(line['y1'] - line['y0']) < 5]\n",
    "            vertical_lines = [line for line in lines if abs(line['x1'] - line['x0']) < 5]\n",
    "            \n",
    "            # Simple heuristic: if we have both horizontal and vertical lines, likely has ruling lines\n",
    "            has_ruling_lines = len(horizontal_lines) > 5 and len(vertical_lines) > 5\n",
    "            \n",
    "            return has_ruling_lines\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Could not detect ruling lines: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84f1f6b",
   "metadata": {},
   "source": [
    "### Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "681c0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_for_tables(pdf_path: str) -> Dict:\n",
    "    \"\"\"Process a single PDF for table extraction using all methods\"\"\"\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    base_name = filename.replace('.pdf', '')\n",
    "    year = filename.split('_')[2][:4]\n",
    "    \n",
    "    print(f\"\\n�� Processing: {filename}\")\n",
    "    print(f\"📅 Year: {year}\")\n",
    "    \n",
    "    # Create year-specific output directory\n",
    "    year_output_dir = os.path.join(table_output_dir, year)\n",
    "    os.makedirs(year_output_dir, exist_ok=True)\n",
    "    \n",
    "    all_results = []\n",
    "    all_comparisons = []\n",
    "    \n",
    "    try:\n",
    "        # Extract tables using all methods\n",
    "        print(\"  🔍 Running Camelot lattice extraction...\")\n",
    "        lattice_results = extract_tables_camelot_lattice(pdf_path)\n",
    "        all_results.extend(lattice_results)\n",
    "        \n",
    "        print(\"  🔍 Running Camelot stream extraction...\")\n",
    "        stream_results = extract_tables_camelot_stream(pdf_path)\n",
    "        all_results.extend(stream_results)\n",
    "        \n",
    "        print(\"  🔍 Running pdfplumber extraction...\")\n",
    "        pdfplumber_results = extract_tables_pdfplumber(pdf_path)\n",
    "        all_results.extend(pdfplumber_results)\n",
    "        \n",
    "        print(\"  🔍 Running hybrid extraction...\")\n",
    "        hybrid_results = create_hybrid_extractor(pdf_path)\n",
    "        \n",
    "        # Compare results\n",
    "        print(\"  📊 Comparing extraction methods...\")\n",
    "        comparisons = compare_table_extractions(all_results)\n",
    "        all_comparisons.extend(comparisons)\n",
    "        \n",
    "        # Save results\n",
    "        save_table_results(all_results, all_comparisons, year_output_dir, base_name)\n",
    "        \n",
    "        # Generate summary\n",
    "        generate_extraction_summary(all_results, all_comparisons, filename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error processing {filename}: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'filename': filename,\n",
    "        'results': all_results,\n",
    "        'comparisons': all_comparisons,\n",
    "        'total_tables': len([r for r in all_results if r.success]),\n",
    "        'successful_methods': len(set(r.method for r in all_results if r.success))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace517a",
   "metadata": {},
   "source": [
    "### Save and Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "756212a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table_results(results: List[TableExtractionResult], comparisons: List[TableComparison], \n",
    "                      output_dir: str, base_name: str):\n",
    "    \"\"\"Save table extraction results\"\"\"\n",
    "    \n",
    "    # Save individual CSV files for each successful extraction\n",
    "    csv_dir = os.path.join(output_dir, f\"{base_name}_tables\")\n",
    "    os.makedirs(csv_dir, exist_ok=True)\n",
    "    \n",
    "    for result in results:\n",
    "        if result.success and not result.raw_data.empty:\n",
    "            csv_filename = f\"{base_name}_page{result.page_number}_table{result.table_index}_{result.method.value}.csv\"\n",
    "            csv_path = os.path.join(csv_dir, csv_filename)\n",
    "            result.raw_data.to_csv(csv_path, index=False)\n",
    "            print(f\"    💾 Saved: {csv_filename}\")\n",
    "    \n",
    "    # Save comparison results\n",
    "    comparison_file = os.path.join(output_dir, f\"{base_name}_comparison.json\")\n",
    "    comparison_data = {\n",
    "        'filename': base_name,\n",
    "        'processing_date': datetime.now().isoformat(),\n",
    "        'total_extractions': len(results),\n",
    "        'successful_extractions': len([r for r in results if r.success]),\n",
    "        'comparisons': [comp.to_dict() for comp in comparisons],\n",
    "        'method_performance': analyze_method_performance(results)\n",
    "    }\n",
    "    \n",
    "    with open(comparison_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(comparison_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"  Saved comparison analysis: {os.path.basename(comparison_file)}\")\n",
    "    \n",
    "def analyze_method_performance(results: List[TableExtractionResult]) -> Dict:\n",
    "    \"\"\"Analyze performance of different extraction methods\"\"\"\n",
    "    method_stats = {}\n",
    "    \n",
    "    for method in TableMethod:\n",
    "        method_results = [r for r in results if r.method == method]\n",
    "        if method_results:\n",
    "            successful = [r for r in method_results if r.success]\n",
    "            method_stats[method.value] = {\n",
    "                'total_attempts': len(method_results),\n",
    "                'successful_extractions': len(successful),\n",
    "                'success_rate': len(successful) / len(method_results) * 100,\n",
    "                'avg_extraction_time': np.mean([r.extraction_time for r in successful]) if successful else 0,\n",
    "                'avg_confidence': np.mean([r.confidence for r in successful if r.confidence]) if successful else None,\n",
    "                'total_tables_found': len(successful)\n",
    "            }\n",
    "    \n",
    "    return method_stats\n",
    "\n",
    "def generate_extraction_summary(results: List[TableExtractionResult], comparisons: List[TableComparison], filename: str):\n",
    "    \"\"\"Generate and print extraction summary\"\"\"\n",
    "    print(f\"\\n  📈 EXTRACTION SUMMARY for {filename}\")\n",
    "    print(f\"  {'='*60}\")\n",
    "    \n",
    "    # Method performance\n",
    "    method_stats = analyze_method_performance(results)\n",
    "    for method, stats in method_stats.items():\n",
    "        print(f\"  {method.upper()}:\")\n",
    "        print(f\"    Success rate: {stats['success_rate']:.1f}% ({stats['successful_extractions']}/{stats['total_attempts']})\")\n",
    "        print(f\"    Avg time: {stats['avg_extraction_time']:.2f}s\")\n",
    "        if stats['avg_confidence']:\n",
    "            print(f\"    Avg confidence: {stats['avg_confidence']:.1f}%\")\n",
    "    \n",
    "    # Best method recommendations\n",
    "    if comparisons:\n",
    "        print(f\"\\n  🏆 RECOMMENDATIONS:\")\n",
    "        for comp in comparisons[:3]:  # Show top 3 comparisons\n",
    "            if comp.best_method:\n",
    "                print(f\"    Page {comp.page_number}, Table {comp.table_index}: {comp.best_method.value}\")\n",
    "                for rec in comp.recommendations[:2]:  # Show top 2 recommendations\n",
    "                    print(f\"      • {rec}\")\n",
    "    \n",
    "    print(f\"  {'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890bd437",
   "metadata": {},
   "source": [
    "### Main Execution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a235022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�� Starting Table Extraction Analysis\n",
      "============================================================\n",
      "📁 Found 3 PDF files to process\n",
      "\n",
      "�� Processing: MSFT_10-K_20230727_000095017023035122.pdf\n",
      "📅 Year: 2023\n",
      "  🔍 Running Camelot lattice extraction...\n",
      "  🔍 Running Camelot stream extraction...\n",
      "  🔍 Running pdfplumber extraction...\n",
      "  🔍 Running hybrid extraction...\n",
      "  📝 No ruling lines detected - using Camelot stream mode\n",
      "  🔧 Running pdfplumber as backup method\n",
      "  📊 Comparing extraction methods...\n",
      "  Saved comparison analysis: MSFT_10-K_20230727_000095017023035122_comparison.json\n",
      "\n",
      "  📈 EXTRACTION SUMMARY for MSFT_10-K_20230727_000095017023035122.pdf\n",
      "  ============================================================\n",
      "  CAMELOT_STREAM:\n",
      "    Success rate: 0.0% (0/1)\n",
      "    Avg time: 0.00s\n",
      "  PDFPLUMBER:\n",
      "    Success rate: 0.0% (0/1)\n",
      "    Avg time: 0.00s\n",
      "\n",
      "  🏆 RECOMMENDATIONS:\n",
      "  ============================================================\n",
      "\n",
      "�� Processing: MSFT_10-K_20240730_000095017024087843.pdf\n",
      "📅 Year: 2024\n",
      "  🔍 Running Camelot lattice extraction...\n",
      "  🔍 Running Camelot stream extraction...\n",
      "  🔍 Running pdfplumber extraction...\n",
      "  🔍 Running hybrid extraction...\n",
      "  📝 No ruling lines detected - using Camelot stream mode\n",
      "  🔧 Running pdfplumber as backup method\n",
      "  📊 Comparing extraction methods...\n",
      "  Saved comparison analysis: MSFT_10-K_20240730_000095017024087843_comparison.json\n",
      "\n",
      "  📈 EXTRACTION SUMMARY for MSFT_10-K_20240730_000095017024087843.pdf\n",
      "  ============================================================\n",
      "  CAMELOT_STREAM:\n",
      "    Success rate: 0.0% (0/1)\n",
      "    Avg time: 0.00s\n",
      "  PDFPLUMBER:\n",
      "    Success rate: 0.0% (0/1)\n",
      "    Avg time: 0.00s\n",
      "\n",
      "  🏆 RECOMMENDATIONS:\n",
      "  ============================================================\n",
      "\n",
      "�� Processing: MSFT_10-K_20220728_000156459022026876.pdf\n",
      "📅 Year: 2022\n",
      "  🔍 Running Camelot lattice extraction...\n",
      "  🔍 Running Camelot stream extraction...\n",
      "  🔍 Running pdfplumber extraction...\n",
      "  🔍 Running hybrid extraction...\n",
      "  📝 No ruling lines detected - using Camelot stream mode\n",
      "  🔧 Running pdfplumber as backup method\n",
      "  📊 Comparing extraction methods...\n",
      "  Saved comparison analysis: MSFT_10-K_20220728_000156459022026876_comparison.json\n",
      "\n",
      "  📈 EXTRACTION SUMMARY for MSFT_10-K_20220728_000156459022026876.pdf\n",
      "  ============================================================\n",
      "  CAMELOT_STREAM:\n",
      "    Success rate: 0.0% (0/1)\n",
      "    Avg time: 0.00s\n",
      "  PDFPLUMBER:\n",
      "    Success rate: 0.0% (0/1)\n",
      "    Avg time: 0.00s\n",
      "\n",
      "  🏆 RECOMMENDATIONS:\n",
      "  ============================================================\n",
      "\n",
      "�� TABLE EXTRACTION COMPLETED!\n",
      "📊 Processed 3/3 files\n",
      "📋 Found 0 total tables\n",
      "💾 Results saved to: ../data/tables/MSFT\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to process all PDFs for table extraction\"\"\"\n",
    "    print(\"�� Starting Table Extraction Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get all PDF files\n",
    "    pdf_files = glob.glob(os.path.join(raw_pdf_dir, \"*.pdf\"))\n",
    "    print(f\"📁 Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    overall_stats = {\n",
    "        'total_files': len(pdf_files),\n",
    "        'processed_files': 0,\n",
    "        'total_tables_found': 0,\n",
    "        'method_performance': {},\n",
    "        'best_methods': []\n",
    "    }\n",
    "    \n",
    "    for pdf_path in pdf_files:\n",
    "        try:\n",
    "            result = process_pdf_for_tables(pdf_path)\n",
    "            overall_stats['processed_files'] += 1\n",
    "            overall_stats['total_tables_found'] += result['total_tables']\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to process {os.path.basename(pdf_path)}: {e}\")\n",
    "    \n",
    "    # Print final summary\n",
    "    print(f\"\\n�� TABLE EXTRACTION COMPLETED!\")\n",
    "    print(f\"📊 Processed {overall_stats['processed_files']}/{overall_stats['total_files']} files\")\n",
    "    print(f\"📋 Found {overall_stats['total_tables_found']} total tables\")\n",
    "    print(f\"💾 Results saved to: {table_output_dir}\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff893eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDF Parser Kernel",
   "language": "python",
   "name": "pdf-parser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
